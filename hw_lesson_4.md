1. Расскажите, как работает регуляризация в решающих деревьях, какие параметры мы штрафуем в данных алгоритмах?
Регуляризация — способ борьбы с переобучением в линейных моделях.

Мерой сложности, то есть «симптомом» переобученности модели, являются большие веса при признаках. Другая ситуация, в которой можно встретиться с переобучением — мультиколлинеарность. Так называется проблема, при которой признаки в выборке являются линейно зависимыми.

Регуляризация вводит штраф за большие веса. Чтобы величины весовых значений модели не становились большими, процесс регуляризации штрафует весовые значения добавляя их в вычисление ошибки. Если весовые значения включаются в общую ошибку, которая минимизируется, тогда меньшие весовые значения будут давать меньшие значения ошибки. L1-регуляризация штрафует весовые значения добавлением суммы их абсолютных значений к ошибке. 
L2 - регуляризация - частый выбор
L1 - регуляризация - сложнее оптимизировать, но можно отбирать признаки.

2. По какому принципу рассчитывается "важность признака (feature_importance)" в ансамблях деревьев?
Это соотношение между количеством выборок, направленных в узел принятия решения, включающий эту функцию в любом из деревьев ансамбля, к общему количеству выборок в обучающем наборе.

Функции, которые задействованы в узлах верхнего уровня деревьев решений, имеют тенденцию видеть больше выборок, поэтому, вероятно, имеют большее значение.